from flask import Flask, request, jsonify
from openai import OpenAI
import os
import re
import requests
import threading
import time

app = Flask(__name__)
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

WEBHOOK_XCLOUD = "https://a.opengl.in/chatbot/check/?k=66b125d558"
WEBHOOK_GERAL = "https://painelacesso1.com/chatbot/check/?k=76be279cb5"

historico_conversas = {}
testes_em_andamento = {}

def gerar_login(webhook):
    try:
        r = requests.get(webhook, timeout=10)
        if r.status_code == 200:
            data = r.json()
            username = data.get("username", "")
            password = data.get("password", "")
            dns = data.get("dns", "")
            msg = f"*UsuÃ¡rio:* `{username}`\n*Senha:* `{password}`"
            if dns:
                msg += f"\n*DNS:* `{dns}`"

            aviso = ""
            if re.search(r"[IlO0]", username):
                aviso += "\n\nâš ï¸ *AtenÃ§Ã£o com o login:*\n"
                if "I" in username:
                    aviso += "âœ… Letra *I* de *Ãndia*\n"
                if "l" in username:
                    aviso += "âœ… Letra *l* minÃºscula de *lÃ¡pis*\n"
                if "O" in username:
                    aviso += "âœ… Letra *O* de *Ovo*\n"
                if "0" in username:
                    aviso += "âœ… NÃºmero *0* (zero)\n"
                aviso += "Digite exatamente como enviado, respeitando maiÃºsculas e minÃºsculas."

            return msg + "\n\nâ³ *Seu teste dura 3 horas.*" + aviso
        else:
            return "âŒ Erro ao gerar o login. Tente novamente em instantes."
    except:
        return "âš ï¸ Erro ao conectar com o servidor de testes."

def agendar_mensagens(numero):
    def tarefa():
        time.sleep(1800)  # 30 minutos
        historico_conversas[numero].append("IA: EstÃ¡ funcionando?")
        testes_em_andamento[numero].append(
            {"message": "Tudo certo aÃ­? ğŸ˜Š SÃ³ passando pra ver se conseguiu usar direitinho. Se tiver dÃºvidas, Ã© sÃ³ me chamar!"}
        )

        time.sleep(5400)  # atÃ© 3 horas no total
        historico_conversas[numero].append("IA: Enviando planos.")
        planos = (
            "*Seu teste terminou!*\n\n"
            "Gostou do serviÃ§o? Temos planos super acessÃ­veis pra continuar:\n\n"
            "ğŸ“… 1 mÃªs: R$ 26\n"
            "ğŸ“… 2 meses: R$ 47\n"
            "ğŸ“… 3 meses: R$ 68\n"
            "ğŸ“… 6 meses: R$ 129\n"
            "ğŸ“… 1 ano: R$ 185\n\n"
            "ğŸ’³ Aceitamos Pix e cartÃ£o.\n\n"
            "Deseja garantir o seu agora? ğŸ˜„"
        )
        testes_em_andamento[numero].append({"message": planos})

    t = threading.Thread(target=tarefa)
    t.start()

@app.route("/", methods=["POST"])
def responder():
    data = request.get_json()
    nome = data.get("name", "")
    numero = nome.strip()
    mensagem = data.get("message", "").lower()
    resposta = []

    if numero not in historico_conversas:
        historico_conversas[numero] = []
        historico_conversas[numero].append(f"Cliente: {mensagem}")
        boasvindas = (
            "OlÃ¡! ğŸ‘‹ Seja bem-vindo! Aqui vocÃª tem acesso a *canais de TV, filmes e sÃ©ries*. ğŸ“ºğŸ¿\n"
            "Vamos comeÃ§ar seu teste gratuito?\n\n"
            "Me diga qual aparelho vocÃª quer usar (ex: TV LG, Roku, Celular, Computador...)."
        )
        historico_conversas[numero].append(f"IA: {boasvindas}")
        resposta.append({"message": boasvindas})
        return jsonify({"replies": resposta})

    historico_conversas[numero].append(f"Cliente: {mensagem}")

    # Se o cliente disser que instalou o app
    if any(p in mensagem for p in ["instalei", "baixei", "pronto", "foi", "baixado"]):
        if any(x in mensagem for x in ["roku", "samsung", "lg", "philco", "xcloud"]):
            login = gerar_login(WEBHOOK_XCLOUD)
        else:
            login = gerar_login(WEBHOOK_GERAL)

        resposta.append({"message": f"Aqui estÃ¡ seu login de teste:\n\n{login}"})
        resposta.append({"message": "â³ Em breve vou perguntar se deu tudo certo com seu teste. ğŸ˜‰"})
        testes_em_andamento[numero] = []
        agendar_mensagens(numero)
        return jsonify({"replies": resposta})

    # Se houver mensagens pendentes programadas (30min ou final de teste)
    if numero in testes_em_andamento and testes_em_andamento[numero]:
        resposta.extend(testes_em_andamento[numero])
        testes_em_andamento[numero] = []
        return jsonify({"replies": resposta})

    # Gerar resposta com IA normalmente
    contexto = "\n".join(historico_conversas[numero][-10:])
    prompt = (
        f"HistÃ³rico recente com o cliente:\n{contexto}\n\n"
        f"Mensagem mais recente: '{mensagem}'\n\n"
        "VocÃª Ã© um atendente de IPTV que responde de forma natural, simpÃ¡tica e objetiva. "
        "Use linguagem clara e entenda o que o cliente quer sem depender de palavras exatas. "
        "Se o cliente disser qual aparelho tem, indique o app correto:\n\n"
        "- TV Roku, LG, Samsung, Philco: indique *Xcloud*\n"
        "- Android, TV Box, Celular, Fire Stick: indique *Xtream IPTV Player*\n"
        "- iPhone ou computador: indique *Smarters Player Lite*\n"
        "- Philips ou AOC: indique *OTT Player* ou *Duplecast* (peÃ§a o QR)\n"
        "- Se usar SmartOne, peÃ§a o MAC\n\n"
        "Se o cliente perguntar o que Ã© IPTV, explique de forma simples.\n"
        "NÃ£o diga 'colar o login', diga 'digitar o login'.\n"
        "Se o cliente enviar algo confuso, diga que um atendente humano vai verificar.\n\n"
        "Responda com o texto exato para o WhatsApp."
    )

    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.6,
        )
        texto = response.choices[0].message.content
        historico_conversas[numero].append(f"IA: {texto}")
        resposta.append({"message": texto})
    except Exception as e:
        resposta.append({"message": f"âš ï¸ Ocorreu um erro: {str(e)}"})

    return jsonify({"replies": resposta})

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=10000)
